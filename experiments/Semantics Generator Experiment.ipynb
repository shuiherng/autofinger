{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Primus Dataset\n",
    "\n",
    "https://github.com/OMR-Research/tf-end-to-end\n",
    "https://grfia.dlsi.ua.es/primus/\n",
    "https://mdpi-res.com/d_attachment/applsci/applsci-08-00606/article_deploy/applsci-08-00606-v3.pdf end to end neurla optical music recognition of monophonic scores\n",
    "https://mediatum.ub.tum.de/doc/1292048/file.pdf Labelling unsegmented sequence data with RNNs\n",
    "https://apacha.github.io/OMR-Datasets/ optical music recognition curated datasets\n",
    "1) Get Primus Dataset\n",
    "2) ETL and get model to work (semantic model)\n",
    "3) Try on sample inputs\n",
    "4) Get labelled data/create expert system to label inputs with fingering\n",
    "5) train model(bilstm/transformer) with inputs\n",
    "6) test model\n",
    "7) create functionality to transform images taken from different angles as flat\n",
    "8) create app to scan image with phone and feed into entire system\n",
    "9) test entire system\n",
    "\n",
    "TODO:\n",
    "1) Makefile to download:\n",
    "    semantic model into SEMANTIC_MODEL_PATH folder (https://grfia.dlsi.ua.es/primus/models/PrIMuS/Semantic-Model.zip)\n",
    "    vocabulary_semantic.txt into SEMANTIC_MODEL_PATH folder (https://github.com/OMR-Research/tf-end-to-end/raw/master/Data/vocabulary_semantic.txt)\n",
    "2) need to change tf reset_default_graph in SemanticGenerator to accomodate loading a second model in tf (https://stackoverflow.com/questions/41990014/load-multiple-models-in-tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tfc\n",
    "\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "tfc.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEMANTIC_MODEL_FOLDER = '../models/Semantic-Model'\n",
    "SEMANTIC_MODEL_PATH = SEMANTIC_MODEL_FOLDER + '/semantic_model.meta'\n",
    "SEMANTIC_VOCABULARY_PATH = SEMANTIC_MODEL_FOLDER + '/vocabulary_semantic.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "# Copied from ctc_utils on https://github.com/OMR-Research/tf-end-to-end/blob/master/ctc_utils.py\n",
    "def normalize(image):\n",
    "    return (255. - image) / 255.\n",
    "\n",
    "def resize(image, height):\n",
    "    width = int(float(height * image.shape[1]) / image.shape[0])\n",
    "    sample_img = cv2.resize(image, (width, height))\n",
    "    return sample_img\n",
    "\n",
    "def sparse_tensors_to_strs(sparse_tensor):\n",
    "    indices = sparse_tensor[0][0]\n",
    "    values = sparse_tensor[0][1]\n",
    "    dense_shape = sparse_tensor[0][2]\n",
    "\n",
    "    strs = [[] for _ in range(dense_shape[0])]\n",
    "\n",
    "    string = []\n",
    "    ptr = 0\n",
    "    b = 0\n",
    "\n",
    "    for idx in range(len(indices)):\n",
    "        if indices[idx][0] != b:\n",
    "            strs[b] = string\n",
    "            string = []\n",
    "            b = indices[idx][0]\n",
    "\n",
    "        string.append(values[ptr])\n",
    "        ptr += 1\n",
    "\n",
    "    strs[b] = string\n",
    "    return strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticGenerator:\n",
    "    def __init__(self):\n",
    "        tfc.reset_default_graph()\n",
    "        self.session = tfc.InteractiveSession()\n",
    "        self.vocab_list = None\n",
    "        with open(SEMANTIC_VOCABULARY_PATH, 'r') as vocab_file:\n",
    "            self.vocab_list = vocab_file.read().splitlines()\n",
    "        saver = tfc.train.import_meta_graph(SEMANTIC_MODEL_PATH)\n",
    "        saver.restore(self.session, SEMANTIC_MODEL_PATH[:-5])\n",
    "        \n",
    "        graph = tfc.get_default_graph()\n",
    "        \n",
    "        self.input = graph.get_tensor_by_name(\"model_input:0\")\n",
    "        self.seq_len = graph.get_tensor_by_name(\"seq_lengths:0\")\n",
    "        self.rnn_keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "        self.height_tensor = graph.get_tensor_by_name(\"input_height:0\")\n",
    "        self.width_reduction_tensor = graph.get_tensor_by_name(\"width_reduction:0\")\n",
    "        self.logits = tfc.get_collection(\"logits\")[0]\n",
    "        \n",
    "        # Constants that are saved inside the model itself\n",
    "        self.WIDTH_REDUCTION, self.HEIGHT = self.session.run([self.width_reduction_tensor, self.height_tensor])\n",
    "        \n",
    "        self.decoded, _ = tf.nn.ctc_greedy_decoder(self.logits, self.seq_len)\n",
    "    \n",
    "    def map_output(self, vec):\n",
    "        return [s for s in map(lambda x: self.vocab_list[x], vec)]\n",
    "    \n",
    "    def predict(self, img_file):\n",
    "        image = Image.open(img_file).convert('L')\n",
    "        image = np.array(image)\n",
    "        image = resize(image, self.HEIGHT)\n",
    "        image = normalize(image)\n",
    "        image = np.asarray(image).reshape(1, image.shape[0], image.shape[1], 1)\n",
    "        \n",
    "        seq_lengths = [image.shape[2] / self.WIDTH_REDUCTION]\n",
    "        \n",
    "        prediction = self.session.run(self.decoded, feed_dict = {\n",
    "            self.input: image,\n",
    "            self.seq_len: seq_lengths,\n",
    "            self.rnn_keep_prob: 1.0,\n",
    "        })\n",
    "        \n",
    "        # predictions is of shape (1, n) where n is number of predictions\n",
    "        predictions = sparse_tensors_to_strs(prediction)\n",
    "        return self.map_output(predictions[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    semantic_generator = SemanticGenerator()\n",
    "    \n",
    "    img = '../images/test1.png'\n",
    "    print(semantic_generator.predict(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The saved meta_graph is possibly from an older release:\n",
      "'model_variables' collection should be of type 'byte_list', but instead is of type 'node_list'.\n",
      "INFO:tensorflow:Restoring parameters from ./models/Semantic-Model/semantic_model\n",
      "['clef-G2', 'keySignature-FM', 'timeSignature-3/2', 'note-A4_quarter', 'note-Bb4_quarter', 'note-A4_quarter', 'note-G4_quarter', 'note-F4_eighth', 'note-G4_eighth', 'barline', 'note-F4_quarter.', 'note-F4_quarter', 'note-F4_eighth', 'barline', 'note-F4_quarter', 'note-Bb4_quarter', 'note-Bb4_quarter', 'note-Bb4_quarter', 'note-C5_quarter', 'note-D5_quarter', 'barline', 'note-C5_half.', 'barline']\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
